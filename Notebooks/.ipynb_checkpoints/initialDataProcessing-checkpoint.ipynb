{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Contents\n",
    "\n",
    "#### 1.  Libraries\n",
    "#### 2.  Importing datafiles\n",
    "#### Problem Definition and objective\n",
    "### Summary of dataset\n",
    "    1. Total number of features\n",
    "    2. Reponsible variables\n",
    "    3. class variabls and their unique value\n",
    "    \n",
    "#### Feature Introductions\n",
    "1. Basic features of individual TCP (descriptions)\n",
    "2. Content features within a connection by domain knowledge (descriptions)\n",
    "3. Traffic features computed using a two-second time window (descriptions and features in this category)\n",
    "\n",
    "#### 3.  Data Processing\n",
    "    1. Too Large Datasets\n",
    "    2. Duplicate Rows\n",
    "#### 4. Essential data type \n",
    "#### 6. Summary data explorationg of data fields\n",
    "#### 5. Feature Selection (Feature Ranking)\n",
    "#### 6. Model Comparison\n",
    "1. Two  many categories of models:\n",
    "    1. Generative:\n",
    "    2. Discriminative Model:\n",
    "     1. Accuracy:\n",
    "     2. Running Time\n",
    "     Naive Bayes and its analysis\n",
    "     Logistic Regression and its analysis\n",
    "     3. kNN  and its analysis\n",
    "     4. Decision Tree Analysis\n",
    "     \n",
    "#### Basic descriptive statistics\n",
    "    1. Descriptive statistics\n",
    "    2. Inferential statistics\n",
    "#### Characteristics of attacks in different attributes\n",
    "    1. Common characteristics\n",
    "    2. Individuals characteristics fr each attack type\n",
    "    \n",
    "#### Summary of Models\n",
    "1. A Graph with various models and with plot of y as running time and x as different models\n",
    "2. Accuracy of models\n",
    "\n",
    "#### Attacks we learned from the data\n",
    "1. Dos: short duration\n",
    "2. Probe: Very low Login successfully rate\n",
    "3. R2L: High number of \"hot\" Indicators\n",
    "4. U2R: High number of \"root\" access\n",
    "###  Key Take Aways:\n",
    "1. take 10% for sampling from the training data\n",
    "2. do data cleaning and found unnecessary samples (ex, duplicated)\n",
    "3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdd = pd.read_csv('../../Data/kddcup.data_10_percent_corrected',header=None )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494021, 42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1     2   3    4     5   6   7   8   9    ...     32   33   34    35  \\\n",
       "0   0  tcp  http  SF  181  5450   0   0   0   0   ...      9  1.0  0.0  0.11   \n",
       "1   0  tcp  http  SF  239   486   0   0   0   0   ...     19  1.0  0.0  0.05   \n",
       "2   0  tcp  http  SF  235  1337   0   0   0   0   ...     29  1.0  0.0  0.03   \n",
       "3   0  tcp  http  SF  219  1337   0   0   0   0   ...     39  1.0  0.0  0.03   \n",
       "4   0  tcp  http  SF  217  2032   0   0   0   0   ...     49  1.0  0.0  0.02   \n",
       "\n",
       "    36   37   38   39   40       41  \n",
       "0  0.0  0.0  0.0  0.0  0.0  normal.  \n",
       "1  0.0  0.0  0.0  0.0  0.0  normal.  \n",
       "2  0.0  0.0  0.0  0.0  0.0  normal.  \n",
       "3  0.0  0.0  0.0  0.0  0.0  normal.  \n",
       "4  0.0  0.0  0.0  0.0  0.0  normal.  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../Data/kddcup.names.txt') as f:\n",
    "    reader = csv.reader(f,delimiter = ':')\n",
    "    class_label = next(reader,None)\n",
    "    #print(class_label)\n",
    "    headerRow = [column[0] for column in reader]\n",
    "    headerRow = headerRow+['classLabel']\n",
    "    kdd = pd.read_csv('../../Data/kddcup.data_10_percent_corrected',header=None)\n",
    "    kdd.columns=headerRow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['normal.', 'buffer_overflow.', 'loadmodule.', 'perl.', 'neptune.',\n",
       "       'smurf.', 'guess_passwd.', 'pod.', 'teardrop.', 'portsweep.',\n",
       "       'ipsweep.', 'land.', 'ftp_write.', 'back.', 'imap.', 'satan.',\n",
       "       'phf.', 'nmap.', 'multihop.', 'warezmaster.', 'warezclient.',\n",
       "       'spy.', 'rootkit.'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdd['classLabel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
       "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
       "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
       "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
       "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
       "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
       "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
       "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
       "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "       'dst_host_srv_rerror_rate', 'classLabel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,   79, ..., 2695, 2751,  120])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdd.duration.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "groupClassLabel = kdd.groupby('classLabel').count()['duration'].sort_values(ascending = False)\n",
    "\n",
    "#groupClassLabel.sort_values('duration', ascending=False, axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classLabel\n",
       "smurf.              280790\n",
       "neptune.            107201\n",
       "normal.              97278\n",
       "back.                 2203\n",
       "satan.                1589\n",
       "ipsweep.              1247\n",
       "portsweep.            1040\n",
       "warezclient.          1020\n",
       "teardrop.              979\n",
       "pod.                   264\n",
       "nmap.                  231\n",
       "guess_passwd.           53\n",
       "buffer_overflow.        30\n",
       "land.                   21\n",
       "warezmaster.            20\n",
       "imap.                   12\n",
       "rootkit.                10\n",
       "loadmodule.              9\n",
       "ftp_write.               8\n",
       "multihop.                7\n",
       "phf.                     4\n",
       "perl.                    3\n",
       "spy.                     2\n",
       "Name: duration, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre processing\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "## Encoding Service\n",
    "le.fit(kdd.service)\n",
    "kdd['service']= le.transform(kdd.service)\n",
    "\n",
    "## Encoding Flag\n",
    "le.fit(kdd.flag)\n",
    "kdd['flag'] = le.transform(kdd.flag)\n",
    "le.fit(kdd.protocol_type)\n",
    "kdd['protocol_type'] = le.transform(kdd.protocol_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### correlation between these three\n",
    "### select correlation using [:1] to select row so that we can have focused correlation\n",
    "### Check for online solutions where the data is arranged with no correct trace size\n",
    "### can we take a compartive view of other datasets (look at evolution of the datasets)\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select \n",
    "## 1. smurf.\n",
    "## 2. neptune.\n",
    "## 3. normal.\n",
    "##  generalize them into their attacks\n",
    "\n",
    "## Preprocessing. \n",
    "## Need to labelEncode them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "Feature selection is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested.\n",
    "\n",
    "Having too many irrelevant features in your data can decrease the accuracy of the models. Three benefits of performing feature selection before modeling your data are:\n",
    "\n",
    "Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.\n",
    "Improves Accuracy: Less misleading data means modeling accuracy improves.\n",
    "Reduces Training Time: Less data means that algorithms train faster.\n",
    "Two different feature selection methods provided by the scikit-learn Python library are Recursive Feature Elimination and feature importance ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do you have domain knowledge?** If yes, construct a better set of ad hoc”” features\n",
    "\n",
    "**Are your features commensurate?** If no, consider normalizing them.\n",
    "\n",
    "**Do you suspect interdependence of features?** If yes, expand your feature set by constructing conjunctive features or products of features, as much as your computer resources allow you.\n",
    "\n",
    "**Do you need to prune the input variables** (e.g. for cost, speed or data understanding reasons)? If no, construct disjunctive features or weighted sums of feature\n",
    "\n",
    "**Do you need to assess features individually** (e.g. to understand their influence on the system or because their number is so large that you need to do a first filtering)? If yes, use a variable ranking method; else, do it anyway to get baseline results.\n",
    "\n",
    "**Do you need a predictor?** If no, stop\n",
    "Do you suspect your data is “dirty” (has a few meaningless input patterns and/or noisy outputs or wrong class labels)? If yes, detect the outlier examples using the top ranking variables obtained in step 5 as representation; check and/or discard them.\n",
    "\n",
    "**Do you know what to try first?** If no, use a linear predictor. Use a forward selection method with the “probe” method as a stopping criterion or use the 0-norm embedded method for comparison, following the ranking of step 5, construct a sequence of predictors of same nature using increasing subsets of features. Can you match or improve performance with a smaller subset? If yes, try a non-linear predictor with that subset.\n",
    "\n",
    "**Do you have new ideas, time, computational resources, and enough examples?** If yes, compare several feature selection methods, including your new idea, correlation coefficients, backward selection and embedded methods. Use linear and non-linear predictors. Select the best approach with model selection\n",
    "\n",
    "**Do you want a stable solution (to improve performance and/or understanding)?** If yes, subsample your data and redo your analysis for several “bootstrap”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## columns with the labeled data:\n",
    "## protocol_type\n",
    "## service\n",
    "## flag\n",
    "## land\n",
    "## Logged in\n",
    "## is host login\n",
    "## is guest login\n",
    "## \n",
    "\n",
    "## once we are done with fitting ## perhaps we can create new rules to show from decision tree of how much\n",
    "## of these attribute have effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>classLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0              1       22     9        181       5450     0   \n",
       "1         0              1       22     9        239        486     0   \n",
       "2         0              1       22     9        235       1337     0   \n",
       "3         0              1       22     9        219       1337     0   \n",
       "4         0              1       22     9        217       2032     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot     ...      dst_host_srv_count  \\\n",
       "0               0       0    0     ...                       9   \n",
       "1               0       0    0     ...                      19   \n",
       "2               0       0    0     ...                      29   \n",
       "3               0       0    0     ...                      39   \n",
       "4               0       0    0     ...                      49   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                     1.0                     0.0   \n",
       "1                     1.0                     0.0   \n",
       "2                     1.0                     0.0   \n",
       "3                     1.0                     0.0   \n",
       "4                     1.0                     0.0   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.11                          0.0   \n",
       "1                         0.05                          0.0   \n",
       "2                         0.03                          0.0   \n",
       "3                         0.03                          0.0   \n",
       "4                         0.02                          0.0   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                   0.0   \n",
       "1                   0.0                       0.0                   0.0   \n",
       "2                   0.0                       0.0                   0.0   \n",
       "3                   0.0                       0.0                   0.0   \n",
       "4                   0.0                       0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  classLabel  \n",
       "0                       0.0     normal.  \n",
       "1                       0.0     normal.  \n",
       "2                       0.0     normal.  \n",
       "3                       0.0     normal.  \n",
       "4                       0.0     normal.  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Verifying data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 50, 17, 11,  3, 56, 18, 13, 39, 14, 40, 45, 43, 19, 48, 59, 31,\n",
       "       29, 47, 20, 52, 32, 65, 10, 30, 24,  8,  7, 38, 49,  0, 37, 23, 16,\n",
       "       44, 15,  5, 62, 26, 27, 12,  9, 55, 54, 25, 21,  6, 42, 53, 63, 34,\n",
       "       35, 33, 51, 64,  4,  2, 28, 36, 60,  1, 61, 41, 57, 58, 46])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.\n",
    "kdd.service.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  6,  1,  7,  5,  8,  2,  4,  3,  0, 10])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.\n",
    "kdd.flag.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.\n",
    "kdd.land.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.\n",
    "kdd.logged_in.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5.\n",
    "kdd.is_host_login.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdd.is_guest_login.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting dataset into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(kdd.drop('classLabel', axis = 1))\n",
    "y = np.array(kdd['classLabel'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.02645419e-04, 8.29986252e-02, 1.50761107e-02, 5.96364252e-03,\n",
       "       5.52095508e-03, 5.73909146e-04, 8.89244454e-05, 4.55577440e-03,\n",
       "       8.22825828e-06, 6.02848553e-03, 8.11848751e-05, 6.31124866e-02,\n",
       "       1.95922826e-03, 7.17276973e-05, 2.77853083e-07, 3.72695390e-05,\n",
       "       3.43557246e-05, 1.57021092e-05, 1.53818144e-05, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.62767105e-04, 5.52208697e-02, 2.94650637e-01,\n",
       "       5.57502648e-02, 7.93331127e-03, 2.81483491e-03, 1.68497347e-03,\n",
       "       1.60113327e-01, 8.88340746e-03, 8.33807192e-03, 1.46953406e-02,\n",
       "       2.39679527e-02, 6.65694190e-03, 4.45774936e-03, 5.69227127e-02,\n",
       "       3.68905704e-03, 2.73337591e-03, 7.70678521e-02, 1.90310286e-02,\n",
       "       8.58060944e-03])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using ExtraTreesClassifier for getting feature importance  <<- This is Taking time \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "clf.feature_importances_  \n",
    "#model = SelectFromModel(clf, prefit=True)\n",
    "#X_new = model.transform(X)\n",
    "#X_new.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Recursive Feature Elimination\n",
    "# from sklearn import datasets\n",
    "# from sklearn.feature_selection import RFE\n",
    "# #from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # load the iris datasets\n",
    "# dataset = datasets.load_iris()\n",
    "# # create a base classifier used to evaluate a subset of attributes\n",
    "# #model = LogisticRegression()\n",
    "# # create the RFE model and select 3 attributes\n",
    "# rfe = RFE(model, 3)\n",
    "# rfe = rfe.fit(X, y)\n",
    "# # summarize the selection of the attributes\n",
    "# print(rfe.support_)\n",
    "# print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #\n",
    "# ## Correlational plots:\n",
    "# %matplotlib inline\n",
    "# #column = ['year','yearReconstructed']\n",
    "# #dec_lr2016 = dec_lr.loc[dec_lr['year'] == 2016]\n",
    "# #dec_lr2016.drop(column,axis = 1 ,inplace = True)\n",
    "# corr = kdd.corr()\n",
    "# sns.heatmap(corr,annot=True, cmap = 'RdYlGn', linewidth = 0.1)\n",
    "# fig = plt.gcf()\n",
    "# fig.set_size_inches(10,8)\n",
    "# fig=plt.gcf()\n",
    "# fig.set_size_inches(18,15)\n",
    "# plt.xticks(fontsize=14)\n",
    "# plt.yticks(fontsize=14)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.9997368545345362\n"
     ]
    }
   ],
   "source": [
    "# Machine Learning Models\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import f1_score,confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# split data train 70 % and test 30 %\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "#random forest classifier with n_estimators \n",
    "clf_rf = RandomForestClassifier()      \n",
    "clr_rf = clf_rf.fit(X_train,y_train)\n",
    "\n",
    "ac = accuracy_score(y_test,clf_rf.predict(X_test))\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test,clf_rf.predict(X_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Support Vector Machine\n",
    "# clf_svc = SVC()\n",
    "    \n",
    "# clr_svc = clf_svc.fit(X_train,y_train)\n",
    "# prediction = clf_svc.predict(X_test)\n",
    "# ac = accuracy_score(y_test,prediction)\n",
    "# print('Accuracy is: ',ac)\n",
    "# cm = confusion_matrix(y_test,prediction)\n",
    "# sns.heatmap(cm,annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Tree\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "predictions = dtree.predict(X_test)\n",
    "ac = accuracy_score(y_test,predictions)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "#print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gaussian NB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "predictions_gnb = gnb.predict(X_test)\n",
    "ac = accuracy_score(y_test,predictions_gnb)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(y_test, predictions_gnb)\n",
    "\n",
    "sns.heatmap(cm,annot = True , fmt = \"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LinearDiscriminanatAnalysis\n",
    "ld = LinearDiscriminantAnalysis()\n",
    "ld.fit(X_train, Y_train)\n",
    "predictions_ld = ld.predict(X_test)\n",
    "ac = accuracy_score(Y_test,predictions_ld)\n",
    "print('Accuracy is: ',ac)\n",
    "cm = confusion_matrix(Y_test, predictions_ld)\n",
    "sns.heatmap(cm,annot = True , fmt = \"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ten fold cross_validation for more improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
